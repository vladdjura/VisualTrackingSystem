{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2899364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from models import Video\n",
    "from functions import show, liner, extractor, gray, space_nums, space_ids, paths, qualifier, frameByFrame, masker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88314ba8",
   "metadata": {},
   "source": [
    "### Creating Video class instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15c432a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames: 613\n"
     ]
    }
   ],
   "source": [
    "video = Video(paths[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aae0730",
   "metadata": {},
   "source": [
    "### Setting parking space boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9f1b045",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.frame = 1\n",
    "img = video.read\n",
    "frame = img.copy()\n",
    "\n",
    "# horizontal red lines\n",
    "# frame = liner(0, 588, 2024, 588, frame, color = 'r', size = 2)\n",
    "# frame = liner(0, 882, 2024, 882, frame, color = 'r', size = 2)\n",
    "\n",
    "# frame = liner(0, 278, 2024, 278, frame, color = 'r', size = 2)\n",
    "# frame = liner(0, 390, 2024, 390, frame, color = 'r', size = 2)\n",
    "\n",
    "# vertical green lines\n",
    "\n",
    "# front row\n",
    "\n",
    "# frame = liner(344, 580, 265, 687, frame, color = 'g', size = 3)\n",
    "# frame = liner(384, 576, 298, 703, frame, color = 'g', size = 3)\n",
    "# frame = liner(424, 578, 334, 721, frame, color = 'g', size = 3)\n",
    "# frame = liner(480, 580, 388, 739, frame, color = 'g', size = 3)\n",
    "# frame = liner(540, 580, 442, 765, frame, color = 'g', size = 4)\n",
    "\n",
    "frame = liner(620, 580, 522, 797, frame, color = 'g')\n",
    "frame = liner(716, 584, 624, 828, frame, color = 'g')\n",
    "frame = liner(830, 588, 760, 860, frame, color = 'g')\n",
    "frame = liner(958, 588, 933, 882, frame, color = 'g')\n",
    "frame = liner(1095, 588, 1115, 882, frame, color = 'g')\n",
    "frame = liner(1224, 590, 1287, 862, frame, color = 'g')\n",
    "frame = liner(1337, 590, 1427, 837, frame, color = 'g')\n",
    "frame = liner(1438, 586, 1543, 810, frame, color = 'g')\n",
    "\n",
    "# frame = liner(1521, 592, 1621, 780, frame, color = 'g', size = 3)\n",
    "# frame = liner(1584, 588, 1685, 753, frame, color = 'g', size = 2)\n",
    "# frame = liner(1633, 586, 1731, 735, frame, color = 'g', size = 2)\n",
    "# frame = liner(1674, 584, 1763, 715, frame, color = 'g', size = 2)\n",
    "# frame = liner(1714, 582, 1803, 706, frame, color = 'g', size = 2)\n",
    "\n",
    "# back row\n",
    "frame = liner(759, 300, 714, 388, frame, color = 'g', size = 3)\n",
    "frame = liner(830, 290, 790, 384, frame, color = 'g', size = 3)\n",
    "frame = liner(907, 283, 882, 374, frame, color = 'g', size = 3)\n",
    "frame = liner(988, 278, 976, 372, frame, color = 'g', size = 3)\n",
    "frame = liner(1074, 278, 1079, 372, frame, color = 'g', size = 3)\n",
    "frame = liner(1153, 284, 1173, 376, frame, color = 'g', size = 3)\n",
    "frame = liner(1227, 291, 1262, 386, frame, color = 'g', size = 3)\n",
    "frame = liner(1300, 300, 1346, 398, frame, color = 'g', size = 3)\n",
    "\n",
    "show(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bb045f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "space_nums = [(1, 995, 760, 3, 4),(3, 1140, 760, 3, 4),(5, 838, 760, 3, 4),(7, 1284, 760, 3, 4), (9, 700, 760, 3, 4),\n",
    "              (0, 1010, 350, 2, 4),(2, 1100, 350, 2, 4),(4, 918, 350, 2, 4),(6, 1184, 350, 2, 4), (8, 830, 350, 2, 4)]\n",
    "\n",
    "ex = [(11, 1390, 760, 3, 4), (13, 540, 760, 3, 4), (10, 734, 350, 2, 4), (12, 1244, 350, 2, 4)]\n",
    "\n",
    "img = video.read\n",
    "frame = img.copy()\n",
    "space_ids(frame, space_nums)\n",
    "show(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70dcc95",
   "metadata": {},
   "source": [
    "### Mask creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf20bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = np.zeros((img.shape[0], img.shape[1]))\n",
    "mask = masker(mask, img, frame)                  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372b65cb",
   "metadata": {},
   "source": [
    "### Printing state for the parking space for given frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22044e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video.state(frame_number, spaces_mask, space_number)\n",
    "video.state(435, mask, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef81a17",
   "metadata": {},
   "source": [
    "### Create image with added space availability text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video.img_texter(frame_number, spaces_mask, saving_file_path, space_number)\n",
    "video.img_texter(435, mask, 'img_unoccupied.jpg', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d8b6d",
   "metadata": {},
   "source": [
    "### Printing states for the parking space frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794d13df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video.texter(starting_frame, stoping_frame, spaces_mask, space_number)\n",
    "start = 430\n",
    "stop = 438\n",
    "change, marks = video.states(start, stop, mask, 1)\n",
    "print(change)\n",
    "print(f'Change array: {marks}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc85d7ab",
   "metadata": {},
   "source": [
    "### Creating video copy with added space availability text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c19ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video.texter(starting_frame, stoping_frame, spaces_maskn, saving_file_path, space_number)\n",
    "start = 430\n",
    "stop = 438\n",
    "change = video.texter(430, 438, mask, 'video_change_detection.avi', 1)\n",
    "print(change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a068e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = video.read\n",
    "frame = img.copy()\n",
    "space_ids(frame, space_nums)\n",
    "show(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9be7eeb",
   "metadata": {},
   "source": [
    "### Creating video copy with added space availability text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6121726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video.texter(starting_frame, stoping_frame, spaces_maskn, saving_file_path, space_number)\n",
    "start = 430\n",
    "stop = 438\n",
    "change = video.texter(430, 438, mask, 'video_change_detection.avi', 1)\n",
    "print(change)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5df976b",
   "metadata": {},
   "source": [
    "### Printing states for the parking space frame by frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e78b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video.texter(starting_frame, stoping_frame, spaces_mask, space_number)\n",
    "start = 430\n",
    "stop = 438\n",
    "change, marks = video.states(start, stop, mask, 1)\n",
    "print(change)\n",
    "print(f'Change array: {marks}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f2f22",
   "metadata": {},
   "source": [
    "### Create image with added space availability text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acefb679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video.img_texter(frame_number, spaces_mask, saving_file_path, space_number)\n",
    "video.img_texter(435, mask, 'img_unoccupied.jpg', 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e513065a",
   "metadata": {},
   "source": [
    "### Printing state for the parking space for given frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380e2505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Video.state(frame_number, spaces_mask, space_number)\n",
    "video.state(435, mask, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f35b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28621e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(300,480):\n",
    "    video.frame = i\n",
    "    img = video.read\n",
    "    space = img[mask == 1]\n",
    "    if i % 2 == 0:\n",
    "        if np.var(space) > 1000:\n",
    "            print(f'frame:{i} - Occupied')\n",
    "        else:\n",
    "            print(f'frame:{i} - Unoccupied')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91e8d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = int(video.cap.get(3)), int(video.cap.get(4))\n",
    "result = cv2.VideoWriter('filename.avi', \n",
    "                         cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "                         10, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61886efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(400, 450):\n",
    "    video.frame = i\n",
    "    frame = video.read\n",
    "    space = frame[mask == 1]\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    org = (500, 1000)\n",
    "    fontScale = 3\n",
    "    color = (0, 0, 255)\n",
    "    thickness = 3\n",
    "    if np.var(space) > 1000:\n",
    "        frame = cv2.putText(frame, 'Space is occupied', org, font, \n",
    "                           fontScale, color, thickness, cv2.LINE_AA)\n",
    "    else:\n",
    "        frame = cv2.putText(frame, 'Space is unoccupied', org, font, \n",
    "                           fontScale, color, thickness, cv2.LINE_AA)\n",
    "    result.write(frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27bafce",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf172e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[mask == 1] = np.array([255,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b8814b",
   "metadata": {},
   "outputs": [],
   "source": [
    "populated_space = img[mask == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81c2a09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.var(populated_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1fe72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_id(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e42581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video.frame = 1\n",
    "img = video.read\n",
    "print(type(img))\n",
    "frame = img.copy()\n",
    "space_ids(frame, space_nums)\n",
    "show(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a29b7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lot_pixels = {1:}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c13f2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "qualifier(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8298f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908563f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lot = frame[588:882,958:1095]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913ff931",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(lot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6122f287",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = (frame == 255).all(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ad6d43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140743db",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_img=frame[lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae65d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "show(l_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3a8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "green = extractor(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d64ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b389a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame[588:598,958]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228dba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[[  5,  11,  10],\n",
    "        [  9,   5,  11],\n",
    "        [ 11,  10,   9],\n",
    "        [255, 255, 255]],\n",
    "\n",
    "       [[  9,   8,   8],\n",
    "        [ 10,   8,   9],\n",
    "        [255, 255, 255],\n",
    "        [  5,   8,  10]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405a7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1=(a==255).all(axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067d1ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c38236",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[mask_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f82c918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c142c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pocetna pozicija, krajnja pozicija, boja, debljina linije\n",
    "image = cv2.line(frame, (0,0), (width, height), (255, 0, 0), 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b404fba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgray = video_1.gray\n",
    "ret, tresh = cv2.threshold(imgray, 200, 255, 0)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "imgcont = imgray.copy()\n",
    "cv2.drawContours(imgcont, contours, -1, (0,255,0), 1)\n",
    "cv2.imshow('contours', imgcont)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ad491",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgray = video_1.gray\n",
    "ret, tresh = cv2.threshold(imgray, 190, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow('contours', tresh)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ab58c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = video_1.read\n",
    "l = np.array([170,170,200])\n",
    "h = np.array([220,220,250])\n",
    "\n",
    "mask = cv2.inRange(img, l, h)\n",
    "result = cv2.bitwise_and(img, img, mask=mask)\n",
    "cv2.imshow('contours', result)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe8c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a5f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_1.frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588a5d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192e4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_1.show(gray = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552f3e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_1.frame = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f740124c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = video_1.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89437f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef34cc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgray = video_1.gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6801f39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9550d14b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360fd8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, thresh = cv2.threshold(imgray, 127, 255, 0)\n",
    "contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cd2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgcont = imgray.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f721097",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cv2.drawContours(imgcont, contours, -1, (0,255,0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c33f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('contours', imgcont)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d6e487",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = cv.imread('test.jpg')\n",
    "imgray = cv.cvtColor(im, cv.COLOR_BGR2GRAY)\n",
    "ret, thresh = cv.threshold(imgray, 127, 255, 0)\n",
    "contours, hierarchy = cv.findContours(thresh, cv.RETR_TREE, cv.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7563014d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit\n",
    "\n",
    "l = hit - 10\n",
    "h = hit + 10\n",
    "\n",
    "# result is a dark background with originaly colored letters\n",
    "mask = cv2.inRange(img_origin, l, h)\n",
    "result = cv2.bitwise_and(img_origin, img_origin, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb5933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# frame counter\n",
    "def frame_counter1(cap):\n",
    "    loop = 0\n",
    "    while(cap.isOpened()):\n",
    "        \n",
    "        # ret is True until last frame\n",
    "        ret, frame = cap.read()  \n",
    "        if not ret:\n",
    "            return loop\n",
    "        \n",
    "        loop+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd750eaa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Number of frames: {frame_counter1(cap)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cd21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of frames in video\n",
    "length = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f162ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa3e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set frame_no in range 0.0-1.0\n",
    "#In this example we have a video of 30 seconds having 25 frames per seconds, thus we have 750 frames.\n",
    "#The examined frame must get a value from 0 to 749.\n",
    "#For more info about the video flags see here: https://stackoverflow.com/questions/11420748/setting-camera-parameters-in-opencv-python\n",
    "#Here we select the last frame as frame sequence=749. In case you want to select other frame change value 749.\n",
    "#BE CAREFUL! Each video has different time length and frame rate. \n",
    "#So make sure that you have the right parameters for the right video!\n",
    "#time_length = 30.0\n",
    "#fps=25\n",
    "#frame_seq = 749\n",
    "#frame_no = (frame_seq /(time_length*fps))\n",
    "\n",
    "#The first argument of cap.set(), number 2 defines that parameter for setting the frame selection.\n",
    "#Number 2 defines flag CV_CAP_PROP_POS_FRAMES which is a 0-based index of the frame to be decoded/captured next.\n",
    "#The second argument defines the frame number in range 0.0-1.0\n",
    "#cap.set(2,frame_no);\n",
    "#Read the next frame from the video. If you set frame 749 above then the code will return the last frame.\n",
    "#ret, frame = cap.read()\n",
    "\n",
    "#Set grayscale colorspace for the frame. \n",
    "#gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#Cut the video extension to have the name of the video\n",
    "#my_video_name = video_name.split(\".\")[0]\n",
    "\n",
    "#Display the resulting frame\n",
    "#cv2.imshow(my_video_name+' frame '+ str(frame_seq),gray)\n",
    "\n",
    "#Set waitKey \n",
    "#cv2.waitKey()\n",
    "\n",
    "#Store this frame to an image\n",
    "#cv2.imwrite(my_video_name+'_frame_'+str(frame_seq)+'.jpg',gray)\n",
    "\n",
    "# When everything done, release the capture\n",
    "#cap.release()\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebeef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = 0\n",
    "while(cap.isOpened()):\n",
    "    loop+=1\n",
    "    # ret is True until last frame\n",
    "    ret, frame = cap.read()\n",
    "    if loop % 100 == 0:\n",
    "        print(f\"loop: {loop}\")\n",
    "        cv2.imshow(f'frame {loop}',frame)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()   \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb307c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imshow('Video1',frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ef9844",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_no = 0.5\n",
    "cap.set(2,frame_no);\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
